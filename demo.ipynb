{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e800cc-b4e6-4403-be5d-04c478dac4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic dependencies\n",
    "\n",
    "import os \n",
    "import os.path\n",
    "import io \n",
    "import traceback\n",
    "from absl import app\n",
    "from absl import flags\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "from PIL import Image\n",
    "from easydict import EasyDict as edict\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = YOUR_OPENAI_KEY # put your key here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c929e2-d4b9-4eb9-bfc9-5e3f118d59db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MOKA utilities\n",
    "\n",
    "from string import ascii_lowercase\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "from moka.gpt_utils import request_gpt\n",
    "from moka.vision.segmentation import get_scene_object_bboxes\n",
    "from moka.vision.segmentation import get_segmentation_masks\n",
    "from moka.vision.keypoint import get_keypoints_from_segmentation\n",
    "from moka.planners.planner import Planner\n",
    "from moka.planners.visual_prompt_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4c144d-9e64-4b3f-9a97-abcb74c0ddfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "config_filename = './config/moka.yaml'\n",
    "with open(config_filename, 'r') as fh:\n",
    "    config = yaml.load(fh, Loader=yaml.SafeLoader)\n",
    "    config = edict(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c2f7fd-83b3-4318-8d91-7bebbf6e4577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_prompts():\n",
    "    \"\"\"Load prompts from files.\n",
    "    \"\"\"\n",
    "    prompts = dict()\n",
    "    prompt_dir = os.path.join(\n",
    "        config.prompt_root_dir, config.prompt_name)\n",
    "    for filename in os.listdir(prompt_dir):\n",
    "        path = os.path.join(prompt_dir, filename)\n",
    "        if os.path.isfile(path) and path[-4:] == '.txt':\n",
    "            with open(path, 'r') as f:\n",
    "                value = f.read()\n",
    "            key = filename[:-4]\n",
    "            prompts[key] = value\n",
    "    return prompts\n",
    "    \n",
    "prompts = load_prompts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1969262b-ef0a-4daf-936e-c57c06c03eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_image = Image.open('example/obs_image.jpg').convert('RGB')\n",
    "obs_image = obs_image.resize([512, 512], Image.LANCZOS)\n",
    "\n",
    "obs = {'image': obs_image}\n",
    "plt.imshow(obs_image)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "task_instruction = 'Use the white ultrasound cleaner to clean the metal watch. The unstrasound cleaner has no lid and can be turned on by pressing the red button.'\n",
    "print('Task: ', task_instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fec5c15-f602-4c36-8038-fc610834f6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plan = request_plan(\n",
    "    task_instruction,\n",
    "    obs_image, \n",
    "    plan_with_obs_image=config.plan_with_obs_image,\n",
    "    prompts=prompts,\n",
    "    debug=True)\n",
    "\n",
    "# Example response after filtering\n",
    "\n",
    "# res = \"\"\"\n",
    "# [\n",
    "#     {\n",
    "#         \"instruction\": \"Move the metal watch into the ultrasound cleaner.\",\n",
    "#         \"object_grasped\": \"metal watch\",\n",
    "#         \"object_unattached\": \"white ultrasound cleaner\",\n",
    "#         \"motion_direction\": \"downward\"\n",
    "#     },\n",
    "#     {\n",
    "#         \"instruction\": \"Press the red button to turn on the ultrasound cleaner.\",\n",
    "#         \"object_grasped\": \"\",\n",
    "#         \"object_unattached\": \"red button\",\n",
    "#         \"motion_direction\": \"downward\"\n",
    "#     }\n",
    "# ]\n",
    "# \"\"\"\n",
    "\n",
    "# object_info = json.loads(res)\n",
    "# plan = object_info\n",
    "print(plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642f9560-fa40-40a9-b846-698be05e7a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_object_names = []\n",
    "for subtask in plan:\n",
    "    if subtask['object_grasped'] != '' and subtask['object_grasped'] not in all_object_names:\n",
    "        all_object_names.append(subtask['object_grasped'])\n",
    "\n",
    "    if subtask['object_unattached'] != '' and subtask['object_unattached'] not in all_object_names:\n",
    "        all_object_names.append(subtask['object_unattached'])\n",
    "\n",
    "print(all_object_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3f8bf6-d612-43e7-948c-2d2e59022df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get bounding boxes\n",
    "boxes, logits, phrases = get_scene_object_bboxes(\n",
    "                obs_image, all_object_names,\n",
    "                visualize=True,\n",
    "                logdir=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f410cb06-25e1-429d-8629-26a66d49fb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get segmentation masks\n",
    "segmasks = get_segmentation_masks(obs_image, all_object_names, boxes, logits, phrases, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be8266b-d9fe-4e3a-829f-615347fbdd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotate visual marks.\n",
    "subtask = plan[0]\n",
    "candidate_keypoints = propose_candidate_keypoints(\n",
    "    subtask,\n",
    "    segmasks, \n",
    "    num_samples=config.num_candidate_keypoints)\n",
    "\n",
    "annotation_size = next(iter(segmasks.values()))['mask'].shape[:2][::-1] \n",
    "obs_image_reshaped = obs_image.resize(annotation_size, Image.LANCZOS)\n",
    "\n",
    "annotated_image = annotate_visual_prompts(\n",
    "            obs_image,\n",
    "            candidate_keypoints,\n",
    "            waypoint_grid_size=config.waypoint_grid_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d532713-14bd-45fb-b4d4-72fd6bded193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select motion \n",
    "# The json format given by GPT4-O can be incorrect. If it fails to visualize the image, please check whether the context is correctly parsed \n",
    "\n",
    "from moka.planners.visual_prompt_utils import request_motion\n",
    "\n",
    "context, _, _ = request_motion(\n",
    "            subtask,\n",
    "            obs_image,\n",
    "            annotated_image,\n",
    "            candidate_keypoints,\n",
    "            waypoint_grid_size=config.waypoint_grid_size, \n",
    "            prompts=prompts, \n",
    "            debug=True\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
